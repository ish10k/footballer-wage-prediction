{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting footballer player wage based on respective FIFA / EAFC plater stats\n",
    "\n",
    "The problem we are addressing is correctly evaluating a playe's wage based on their stats. With ever more growing talent in the field, it is vital as a football club to accurately price your players to stay competitive. Our goal is to study & build machine learning models to accurately predict a footballer's wage based on a dataset of players wage and stats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing data\n",
    "\n",
    "We are going to be utilising the [EA Sports FC 24 complete player dataset](https://www.kaggle.com/datasets/stefanoleone992/ea-sports-fc-24-complete-player-dataset/data) from kaggle for player stats and valautions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required Python modules:\n",
    "* Pandas - importing and manipulating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "# instructing pandas to not truncate column widths when displaying data in interactive mode\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "random_state = 42 # Set random state to ensure all random variables can be reproduced\n",
    "datasets_fp = 'datasets/' # Datasets folder path\n",
    "df = pd.read_csv(datasets_fp + 'male_players.csv', encoding='unicode_escape')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a quick look at the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5) # first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a quick analysis of the data and it's columns using the pandas describe() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all') # using include='all' to show us all columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find out exactly how many columns we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.columns) # length of columns list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Data Preperation\n",
    "\n",
    "Now we have sucessfully imported the dataset, we need to prepare it for the task at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will focusing on the Premier League data only so let's filter the dataset to satisfy this requirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['league_name'] == 'Premier League'] # filter league_name to 'Premier League'\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current dataset has too many features with a large portion being irrelevant to the task at hand. We will drop the columns that aren't relevant using the .drop() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\n",
    "    'player_id',\n",
    "    'wage_eur',\n",
    "    'player_url',\n",
    "    'update_as_of',\n",
    "    'short_name',\n",
    "    'long_name',\n",
    "    'dob',\n",
    "    'club_name',\n",
    "    'league_name',\n",
    "    'club_position',\n",
    "    'club_loaned_from',\n",
    "    'club_joined_date',\n",
    "    'nationality_id',\n",
    "    'nationality_name',\n",
    "    'nation_position',\n",
    "    'body_type',\n",
    "    'real_face',\n",
    "    'player_tags',\n",
    "    'player_traits',\n",
    "    'fifa_update',\n",
    "    'league_level',\n",
    "    'club_team_id',\n",
    "    'league_id',\n",
    "    'club_jersey_number',\n",
    "    'club_contract_valid_until_year',\n",
    "    'nation_team_id',\n",
    "    'nation_jersey_number',\n",
    "    'release_clause_eur',\n",
    "    'height_cm',\n",
    "    'weight_kg',\n",
    "    'ls',\n",
    "    'st',\n",
    "    'rs',\n",
    "    'lw',\n",
    "    'lf',\n",
    "    'cf',\n",
    "    'rf',\n",
    "    'rw',\n",
    "    'lam',\n",
    "    'cam',\n",
    "    'ram',\n",
    "    'lm',\n",
    "    'lcm',\n",
    "    'cm',\n",
    "    'rcm',\n",
    "    'rm',\n",
    "    'lwb',\n",
    "    'ldm',\n",
    "    'cdm',\n",
    "    'rdm',\n",
    "    'rwb',\n",
    "    'lb',\n",
    "    'lcb',\n",
    "    'cb',\n",
    "    'rcb',\n",
    "    'rb',\n",
    "    'gk',\n",
    "    'work_rate',\n",
    "    'attacking_crossing',\n",
    "    'attacking_finishing',\n",
    "    'attacking_heading_accuracy',\n",
    "    'attacking_short_passing',\n",
    "    'attacking_volleys',\n",
    "    'skill_dribbling',\n",
    "    'skill_curve',\n",
    "    'skill_fk_accuracy',\n",
    "    'skill_long_passing',\n",
    "    'skill_ball_control',\n",
    "    'movement_acceleration',\n",
    "    'movement_sprint_speed',\n",
    "    'movement_agility',\n",
    "    'movement_reactions',\n",
    "    'movement_balance',\n",
    "    'power_shot_power',\n",
    "    'power_jumping',\n",
    "    'power_stamina',\n",
    "    'power_strength',\n",
    "    'power_long_shots',\n",
    "    'mentality_aggression',\n",
    "    'mentality_interceptions',\n",
    "    'mentality_positioning',\n",
    "    'mentality_vision',\n",
    "    'mentality_penalties',\n",
    "    'mentality_composure',\n",
    "    'defending_marking_awareness',\n",
    "    'defending_standing_tackle',\n",
    "    'defending_sliding_tackle',\n",
    "    'goalkeeping_diving',\n",
    "    'goalkeeping_handling',\n",
    "    'goalkeeping_kicking',\n",
    "    'goalkeeping_positioning',\n",
    "    'goalkeeping_reflexes',\n",
    "    'goalkeeping_speed'\n",
    "], axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to extract main player position from player_positions column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------\n",
    "# player_positions -> main_position\n",
    "#----------------------------------\n",
    "\n",
    "# list of all outfield positons can be found at https://www.fifplay.com/encyclopedia/position/\n",
    "forward_positions = [\n",
    "    'ST', \n",
    "    'CF',\n",
    "    'RF',\n",
    "    'LF',\n",
    "    'RW',\n",
    "    'LW',\n",
    "]\n",
    "\n",
    "midfielder_positions = [\n",
    "    'CM',\n",
    "    'CDM',\n",
    "    'CAM',\n",
    "    'RM',\n",
    "    'LM',\n",
    "]\n",
    "\n",
    "defender_positions = [\n",
    "    'CB',\n",
    "    'RB',\n",
    "    'LB',\n",
    "    'RWB',\n",
    "    'LWB',\n",
    "]\n",
    "\n",
    "def calc_main_position(positions: str):\n",
    "\n",
    "    primary_position = positions.split(',')[0] # using first position mentioned as primary position\n",
    "\n",
    "    if primary_position in forward_positions:\n",
    "        return 'FW'\n",
    "    elif primary_position in midfielder_positions:\n",
    "        return 'MD'\n",
    "    elif primary_position in defender_positions:\n",
    "        return 'DF'\n",
    "    elif primary_position == 'GK':\n",
    "        return 'GK'\n",
    "    else:\n",
    "        return None # no valid position found\n",
    "\n",
    "# Create new column with function applied to each value\n",
    "df['main_position'] = df['player_positions'].apply(lambda pos: calc_main_position(pos))\n",
    "# Show new column\n",
    "print(df[['player_positions','main_position']])\n",
    "# Check for nulls\n",
    "print('\\nNulls: ', df['main_position'].isnull().sum())\n",
    "# Drop old column\n",
    "df.drop(['player_positions'] ,axis=1,inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter data for non-goalkeeper players only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['main_position'] != 'GK'] # filter out goalkeepers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    n_nulls = df[col].isnull().sum() # get count of column null values\n",
    "    print(f\"{col} - {n_nulls} nulls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop columns with null value_eur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['value_eur'], inplace=True)\n",
    "df['value_eur'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train_test_split function from sklearn\n",
    "# Doc: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set target dataset to value_eur column\n",
    "y = df['value_eur']\n",
    "# Set features dataset to dataset minus value_eur column using .drop() function\n",
    "X = df.drop(['value_eur'], axis=1)\n",
    "\n",
    "# Split dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=.2, random_state=random_state\n",
    ")\n",
    "\n",
    "# Test if split was as expected by calculating percentage of each set\n",
    "# This should give us a total split of 80%-10%-10% (train, valid, test)\n",
    "train_percent = X_train.shape[0] / X.shape[0] * 100\n",
    "test_percent = X_test.shape[0] / X.shape[0]  * 100\n",
    "total_percent = train_percent+test_percent\n",
    "\n",
    "print(f'Train: {train_percent}%\\\n",
    "      \\nTest: {test_percent}%\\\n",
    "      \\n------------------------\\\n",
    "      \\nTotal: {total_percent}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install library for plots and visualisations\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(df['value_eur'],  kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(df[df['value_eur'] > 100000000]['value_eur'], binwidth=10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(df['age'], binwidth=1) # binwidth = width of each bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df, x='age', orient='h') # horizontal orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.displot(df['overall'], binwidth=5)\n",
    "#sns.boxplot(df['overall'], orient='h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.displot(df['potential'], binwidth=5)\n",
    "#sns.boxplot(df['potential'], orient='h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(df, x='fifa_version', kind='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(df['preferred_foot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(df['preferred_foot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(df, x='skill_moves', kind='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(df, x='weak_foot', kind='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(df, x='international_reputation', kind='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_records = df.shape[0] # number of records in our dataframe\n",
    "\n",
    "#loop 5 times (1 for each rating from 1-5)\n",
    "for i in range(5):\n",
    "    rating = i+1 # index starts from 0 so add 1 to get rating\n",
    "    \n",
    "    # get number of records with this rating\n",
    "    count = df[df['international_reputation']==rating].shape[0]\n",
    "    percent = count / n_records * 100\n",
    "    \n",
    "    print(f\"Intl rep rating {rating}: {percent}%\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(df['pace'], binwidth=5, kde=True)\n",
    "#sns.boxplot(df, x='pace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(df, x='shooting', binwidth=5, kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(df['dribbling'], binwidth=5, kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(df['passing'], binwidth=5, kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(df['physic'], binwidth=5, kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(df, x='main_position', kind='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pair Plot\n",
    "\n",
    "sns.pairplot(\n",
    "    df, \n",
    "    vars=[    # 2d grid of these columns\n",
    "        'value_eur',\n",
    "        'age',\n",
    "        'overall',\n",
    "        'international_reputation',\n",
    "        'skill_moves',\n",
    "        'shooting',\n",
    "        'pace',\n",
    "        'main_position'\n",
    "    ], \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(df, x='fifa_version', y='value_eur')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(df, x='age', y='value_eur')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(df, x='overall', y='value_eur')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(df, x='potential', y='value_eur')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(df, x='main_position', y='value_eur')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(df, x='international_reputation', y='value_eur')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(df, x='preferred_foot', y='value_eur')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(df, x='weak_foot', y='value_eur')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(df, x='shooting', y='value_eur')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(df, x='dribbling', y='value_eur')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(df, x='passing', y='value_eur')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(df, x='physic', y='value_eur')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(df, x='fifa_version', y='overall')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleansing / pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check each dataset for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {    # using dictionary so we can reference the name as string\n",
    "    \"Train\": X_train, \n",
    "    \"Test\": X_test, \n",
    "}\n",
    "\n",
    "for dataset in datasets.items():\n",
    "    name, _df = dataset\n",
    "\n",
    "    print(\"\\n\", name,\"\\n============\")\n",
    "    for col in _df.columns:\n",
    "        n_nulls = _df[col].isnull().sum() # get count of column null values\n",
    "        print(f\"{col} - {n_nulls} nulls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data encoding / scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dummy encoding function to transform category data to numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_dummy_encoding(df: pd.DataFrame, columns: list) -> None:\n",
    "    \"\"\"Create dummies for column(s) and drop old\"\"\"\n",
    "    \n",
    "    df = deepcopy(df)\n",
    "    # create dummies\n",
    "    df = pd.concat([df, pd.get_dummies(df, columns=columns, drop_first=True)], axis=1)\n",
    "    \n",
    "    # drop old columns\n",
    "    df = df.drop(columns, axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale data function using RobustScalar class from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "def apply_robust_scalar(df: pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"Scales data using robust scalar\"\"\"\n",
    "    scaler = MinMaxScaler() # create RobustScaler object\n",
    "    return scaler.fit_transform(df) # use object to fit and transform dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to combine both preprocesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def apply_preprocessing(df: pd.DataFrame, scale: bool=True) -> pd.DataFrame:\n",
    "    \"\"\"Apply preprocessing (encoding & scaling)\"\"\"\n",
    "    df = apply_dummy_encoding(df, columns=['main_position', 'preferred_foot'])\n",
    "    if scale:\n",
    "        df = apply_robust_scalar(df)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export final processed dataframes as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply processing to each feature dataset\n",
    "#X_train.drop(['overall', 'potential'], axis=1, inplace=True)\n",
    "#X_test.drop(['overall', 'potential'], axis=1, inplace=True)\n",
    "\n",
    "X_train = apply_preprocessing(X_train, scale=True)\n",
    "X_test = apply_preprocessing(X_test, scale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import RandomForestRegressor\n",
    "#from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating model with best hyperparameters using automated hyperparameter tuning whilst cross-validating with K-Folds 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, mean_absolute_error, r2_score\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "# Set machine learning algorithm\n",
    "algo = LinearRegression()\n",
    "\n",
    "# Define the hyperparameter grid for tuning\n",
    "param_grid = {\n",
    "    'fit_intercept': [True, False],\n",
    "    'positive': [True, False]\n",
    "}\n",
    "\n",
    "# Create a dictionary of the scorers to use \n",
    "scorers = {\n",
    "    'r2_score': make_scorer(r2_score),\n",
    "    'mae': make_scorer(mean_absolute_error),\n",
    "    'mse': make_scorer(mean_squared_error, squared=True),\n",
    "    'rmse': make_scorer(lambda y_true, y_pred: sqrt(mean_squared_error(y_true, y_pred)))\n",
    "}\n",
    "\n",
    "# Create the RandomizedSearchCV object\n",
    "random_search = GridSearchCV(\n",
    "    estimator=algo, \n",
    "    param_grid=param_grid, \n",
    "    scoring=scorers, \n",
    "    refit='rmse', \n",
    "    cv=3, # number of K-Folds\n",
    "    verbose=1, \n",
    "    n_jobs=-1, \n",
    ")\n",
    "\n",
    "# Fit the RandomSearch object to the data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_rfr = random_search.best_estimator_\n",
    "# Show hyperparameters of best model\n",
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best model to make predictions\n",
    "y_prediction = best_rfr.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the best model on test dataset\n",
    "r2 = r2_score(y_test, y_prediction)\n",
    "mae = mean_absolute_error(y_test, y_prediction)\n",
    "mse = mean_squared_error(y_test, y_prediction)\n",
    "rmse = sqrt(mse)\n",
    "\n",
    "print(f\"R²: {r2}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise model prediction performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=y_test, y=y_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances from the trained model\n",
    "feature_importances = best_rfr.feature_importances_\n",
    "\n",
    "# Get feature names from your dataset (assuming you have X_train available)\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Create a DataFrame for easier plotting\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "\n",
    "# Sort the DataFrame by importance in descending order\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot the feature importances using Seaborn and Matplotlib\n",
    "sns.barplot(x='Importance', y='Feature', data=importance_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
